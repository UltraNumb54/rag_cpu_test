import os
import chromadb
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
from pathlib import Path

processed_dir = Path('./processed_documents')
chroma_dir = Path('./chroma_db')

model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')

def chunk_text(text, chunk_size=512, overlap=50):
    words = text.split()
    chunks = []
    for i in range(0, len(words), chunk_size - overlap):
        chunk = ' '.join(words[i:i + chunk_size])
        chunks.append(chunk)
        if i + chunk_size >= len(words):
            break
    return chunks

def process_to_chromadb():
    client = chromadb.PersistentClient(path=str(chroma_dir))
    collection = client.get_or_create_collection(name="documents")
    
    all_chunks = []
    all_metadatas = []
    all_ids = []
    
    for txt_file in processed_dir.glob('*_processed.txt'):
        with open(txt_file, 'r', encoding='utf-8') as f:
            text = f.read()
        
        chunks = chunk_text(text)
        for i, chunk in enumerate(chunks):
            all_chunks.append(chunk)
            all_metadatas.append({"source": txt_file.name, "chunk_id": i})
            all_ids.append(f"{txt_file.stem}_{i}")
    
    embeddings = model.encode(all_chunks).tolist()
    
    collection.add(
        embeddings=embeddings,
        documents=all_chunks,
        metadatas=all_metadatas,
        ids=all_ids
    )
    
    return collection

def search_documents(query, collection, n_results=3):
    query_embedding = model.encode([query]).tolist()
    results = collection.query(
        query_embeddings=query_embedding,
        n_results=n_results
    )
    return results

if __name__ == "__main__":
    collection = process_to_chromadb()
    print("База данных создана. Пример поиска:")
    results = search_documents("пример запроса", collection)
    print(results)

import chromadb
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')
chroma_dir = './chroma_db'

client = chromadb.PersistentClient(path=chroma_dir)
collection = client.get_collection("documents")

def inspect_collection():
    print(f"Количество записей: {collection.count()}")
    results = collection.get(include=['documents', 'metadatas'])
    for i, (doc, meta) in enumerate(zip(results['documents'][:3], results['metadatas'][:3])):
        print(f"\n--- Документ {i+1} ---")
        print(f"Источник: {meta['source']}")
        print(f"Чанк: {meta['chunk_id']}")
        print(f"Текст: {doc[:200]}...")

def search_with_rag(query, n_results=3):
    query_embedding = model.encode([query]).tolist()
    results = collection.query(
        query_embeddings=query_embedding,
        n_results=n_results,
        include=['documents', 'metadatas', 'distances']
    )
    
    print(f"Запрос: '{query}'\n")
    print("Релевантные документы:")
    for i, (doc, meta, dist) in enumerate(zip(results['documents'][0], results['metadatas'][0], results['distances'][0])):
        print(f"\n--- Результат {i+1} (расстояние: {dist:.4f}) ---")
        print(f"Источник: {meta['source']}")
        print(f"Текст: {doc}")

if __name__ == "__main__":
    print("=== Просмотр содержимого базы ===")
    inspect_collection()
    
    print("\n=== Тестовый поиск ===")
    search_with_rag("как работать с программами")
    
    print("\n=== Интерактивный поиск ===")
    while True:
        query = input("\nВведите запрос (или 'exit' для выхода): ")
        if query.lower() == 'exit':
            break
        search_with_rag(query)
